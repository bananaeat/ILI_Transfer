{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load queries from file\n",
    "queries = []\n",
    "with open(\"data/US/queries.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        queries.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flu jabs'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[578]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First filter: only allow queries with sufficient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/US/queries_filtered.txt') as f:\n",
    "    raw_us_queries = f.read().splitlines()\n",
    "query_ids = set([int(r.split('\\t')[0]) for r in raw_us_queries])\n",
    "q_freq_us_raw = pd.read_csv('./data/US/Q_freq.csv')\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def days_between(d1, d2):\n",
    "    d1 = datetime.strptime(d1, \"%Y-%m-%d\")\n",
    "    d2 = datetime.strptime(d2, \"%Y-%m-%d\")\n",
    "    return (d2 - d1).days\n",
    "\n",
    "def day_index(d):\n",
    "    return days_between('2004-01-01', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_day = day_index('2009-09-01')\n",
    "end_day = day_index('2019-08-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_freq_first_non_missing = q_freq_us_raw.groupby('Query').first().reset_index()\n",
    "q_freq_last_non_missing = q_freq_us_raw.groupby('Query').last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find set of qids with non-missing frequency in the first and last month\n",
    "qids_first_non_missing = set(q_freq_first_non_missing[q_freq_first_non_missing['Day'] <= start_day]['Query'])\n",
    "qids_last_non_missing = set(q_freq_last_non_missing[q_freq_last_non_missing['Day'] >= end_day]['Query'])\n",
    "\n",
    "qids_with_data = qids_first_non_missing.intersection(qids_last_non_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second filter: semantic filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [00:04<00:00, 39.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode queries\n",
    "batch_size = 128\n",
    "embeddings = torch.tensor([])\n",
    "for i in tqdm(range(0, len(queries), batch_size)):\n",
    "    batch = queries[i : i + batch_size]\n",
    "    embeddings = torch.cat((embeddings, torch.tensor(model.encode(batch))))\n",
    "\n",
    "# Save embeddings\n",
    "torch.save(embeddings, \"data/US/queries_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    # Both are torch tensors\n",
    "    return torch.dot(a, b) / (torch.norm(a) * torch.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flu concept embeddings\n",
    "flu_embedding = torch.tensor(model.encode(\"flu\"))\n",
    "fever_embedding = torch.tensor(model.encode(\"fever\"))\n",
    "\n",
    "query_similarities = []\n",
    "for i, query in enumerate(queries):\n",
    "    query_id = i + 1\n",
    "    query_embedding = embeddings[i]\n",
    "    flu_symptom_similarity = cosine_similarity(query_embedding, flu_embedding)\n",
    "    flu_vaccine_similarity = cosine_similarity(query_embedding, fever_embedding)\n",
    "    # Average of the three similarities\n",
    "    average_similarity = (flu_symptom_similarity + flu_vaccine_similarity) / 2\n",
    "    query_similarities.append((query_id, query, average_similarity.item()))\n",
    "\n",
    "# Sort queries by similarity\n",
    "query_similarities.sort(key=lambda x: x[2], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out queries with qids_with_data\n",
    "filtered_queries = []\n",
    "for query in query_similarities:\n",
    "    filtered_queries.append(query)\n",
    "\n",
    "# Only use first 1500 queries\n",
    "filtered_queries = filtered_queries[:1500]\n",
    "\n",
    "# Save filtered queries\n",
    "with open(\"data/US/queries_filtered.txt\", \"w\") as f:\n",
    "    for query in filtered_queries:\n",
    "        f.write(f\"{query[0]}\\t{query[1]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
